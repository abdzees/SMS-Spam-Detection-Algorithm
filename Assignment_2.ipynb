{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82e7877d",
   "metadata": {
    "id": "82e7877d"
   },
   "source": [
    "# Assignmnet 2 (100 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297b6d20",
   "metadata": {
    "id": "297b6d20"
   },
   "source": [
    "**Name:** Abdullah Zeeshan<br>\n",
    "**Email:** abz3929@thi.de<br>\n",
    "**Group:** B <br>\n",
    "**Hours spend *(optional)* :** <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f79f88",
   "metadata": {
    "id": "09f79f88"
   },
   "source": [
    "### SMS Spam Detection *(60 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148e88d0",
   "metadata": {
    "id": "148e88d0"
   },
   "source": [
    "<p>You are hired as an AI expert in the development department of a telecommunications company. The first thing on your orientation plan is a small project that your boss has assigned you for the following given situation. Your supervisor has given away his private cell phone number on too many websites and is now complaining about daily spam SMS. Therefore, it is your job to write a spam detector in Python. </p>\n",
    "\n",
    "<p>In doing so, you need to use a Naive Bayes classifier that can handle both bag-of-words (BoW) and tf-idf features as input. For the evaluation of your spam detector, an SMS collection is available as a dataset - this has yet to be suitably split into train and test data. To keep the costs as low as possible and to avoid problems with copyrights, your boss insists on a new development with Python.</p>\n",
    "\n",
    "<p>Include a short description of the data preprocessing steps, method, experiment design, hyper-parameters, and evaluation metric. Also, document your findings, drawbacks, and potential improvements.</p>\n",
    "\n",
    "<p>Note: You need to implement the bag-of-words (BoW) and tf-idf feature extractor from scratch. You can use existing python libraries for other tasks.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad12eba",
   "metadata": {
    "id": "fad12eba"
   },
   "source": [
    "**Dataset and Resources**\n",
    "\n",
    "* SMS Spam Collection Dataset: https://archive.ics.uci.edu/dataset/228/sms+spam+collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4109920",
   "metadata": {
    "id": "f4109920",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation of Naive Bayes classifier on BoW features:\n",
      "Accuracy: 0.9758\n",
      "Precision: 0.9067\n",
      "Recall: 0.9128\n",
      "F1 Score: 0.9097\n",
      "\n",
      "Evaluation of Naive Bayes classifier on TF-IDF features:\n",
      "Accuracy: 0.9435\n",
      "Precision: 0.7263\n",
      "Recall: 0.9262\n",
      "F1 Score: 0.8142\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Download necessary NLTK data (run once)\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except nltk.downloader.DownloadError:\n",
    "    nltk.download('stopwords')\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except nltk.downloader.DownloadError:\n",
    "    nltk.download('punkt')\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt_tab')\n",
    "except nltk.downloader.DownloadError:\n",
    "    nltk.download('punkt_tab')\n",
    "\n",
    "def load_data(file_path):\n",
    "    messages = []\n",
    "    labels = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            parts = line.split(None, 1)\n",
    "            label = parts[0].strip()\n",
    "            message = parts[1].strip()\n",
    "            messages.append(message)\n",
    "            labels.append(label)\n",
    "\n",
    "    return messages, labels\n",
    "\n",
    "def preprocess(messages):\n",
    "    messages_lower = [message.lower() for message in messages]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    porter = PorterStemmer()\n",
    "    processed_messages = []\n",
    "    for message in messages_lower:\n",
    "        tokens = nltk.word_tokenize(message)\n",
    "        alphanumeric_tokens = [token for token in tokens if re.match(r'[a-zA-Z0-9]+$', token)]\n",
    "        tokens_no_stopwords = [token for token in alphanumeric_tokens if token not in stop_words]\n",
    "        stemmed_tokens = [porter.stem(token) for token in tokens_no_stopwords]\n",
    "        processed_messages.append(stemmed_tokens)\n",
    "    return processed_messages\n",
    "\n",
    "def bag_of_words(documents):\n",
    "    num_documents = len(documents)\n",
    "    vocabulary_size = len(vocabulary)\n",
    "    bow_matrix = [[0 for _ in range(vocabulary_size)] for _ in range(num_documents)]\n",
    "    word_to_index = {word: i for i, word in enumerate(vocabulary)}\n",
    "    for i, document in enumerate(documents):\n",
    "        for word in document:\n",
    "            if word in word_to_index:\n",
    "                index = word_to_index[word]\n",
    "                bow_matrix[i][index] += 1\n",
    "\n",
    "    return bow_matrix\n",
    "\n",
    "def tf_idf(documents):\n",
    "    num_documents = len(documents)  \n",
    "    vocabulary_size = len(vocabulary)  \n",
    "    tfidf_matrix = [[0.0 for _ in range(vocabulary_size)] for _ in range(num_documents)]\n",
    "    word_to_index = {word: i for i, word in enumerate(vocabulary)}\n",
    "\n",
    "    # Calculate term frequency (TF)\n",
    "    tf_matrix = [[0.0 for _ in range(vocabulary_size)] for _ in range(num_documents)]\n",
    "    for i, document in enumerate(documents):\n",
    "        for word in document:\n",
    "            if word in word_to_index:\n",
    "                index = word_to_index[word]\n",
    "                tf_matrix[i][index] += 1\n",
    "\n",
    "    # Calculate document frequency (DF)\n",
    "    document_frequency = [0.0] * vocabulary_size\n",
    "    for i, document in enumerate(documents):\n",
    "        for document in documents:\n",
    "            if word in document:\n",
    "                document_frequency[i] += 1\n",
    "\n",
    "    # Calculate inverse document frequency (IDF)\n",
    "    inverse_document_frequency = [0.0] * vocabulary_size\n",
    "    for i in range(vocabulary_size):\n",
    "        if document_frequency[i] > 0:\n",
    "            inverse_document_frequency[i] = np.log(num_documents / document_frequency[i])\n",
    "\n",
    "    # Calculate TF-IDF\n",
    "    for i in range(num_documents):\n",
    "        for j in range(vocabulary_size):\n",
    "            if tf_matrix[i][j] > 0:\n",
    "                tfidf_matrix[i][j] = tf_matrix[i][j] * inverse_document_frequency[j]\n",
    "\n",
    "    return tfidf_matrix\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'sms_spam_collection\\SMSSpamCollection'\n",
    "messages, labels = load_data(file_path)\n",
    "\n",
    "# Preprocess the messages  \n",
    "processed_messages = preprocess(messages)\n",
    "\n",
    "# Create the vocabulary\n",
    "all_words = [word for tokens in processed_messages for word in tokens]\n",
    "vocabulary = list(set(all_words))\n",
    "\n",
    "# Create the Bag-of-Words features\n",
    "bow_features = bag_of_words(processed_messages)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    np.array(bow_features),  # Convert to NumPy array\n",
    "    labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=labels\n",
    ")\n",
    "\n",
    "# Train a Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_bow = nb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nEvaluation of Naive Bayes classifier on BoW features:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_bow):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_bow, pos_label='spam'):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_bow, pos_label='spam'):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred_bow, pos_label='spam'):.4f}\")\n",
    "\n",
    "\n",
    "# Create the TF-IDF features\n",
    "tfidf_features = tf_idf(processed_messages)\n",
    "\n",
    "# Split data into training and testing sets for TF-IDF\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(\n",
    "    np.array(tfidf_features),  # Convert to NumPy array\n",
    "    labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=labels\n",
    ")\n",
    "\n",
    "# Train a Naive Bayes classifier on TF-IDF features\n",
    "nb_classifier_tfidf = MultinomialNB()\n",
    "nb_classifier_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "\n",
    "# Make predictions on the test set for TF-IDF\n",
    "y_pred_tfidf = nb_classifier_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model on TF-IDF features\n",
    "print(\"\\nEvaluation of Naive Bayes classifier on TF-IDF features:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_tfidf, y_pred_tfidf):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test_tfidf, y_pred_tfidf, pos_label='spam'):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test_tfidf, y_pred_tfidf, pos_label='spam'):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test_tfidf, y_pred_tfidf, pos_label='spam'):.4f}\")\n",
    "\n",
    "## You can use sklearn or other python libraries for naive bayes classifier, evaluation metric, etc.  ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1dc9b2",
   "metadata": {},
   "source": [
    "## Spam Detection Experiment Details\n",
    "\n",
    "Here's a breakdown of the experiment, including data preprocessing, methodology, design, hyperparameters, evaluation, findings, drawbacks, and potential improvements:\n",
    "\n",
    "**1. Data Preprocessing**\n",
    "\n",
    "The dataset consists of SMS messages labeled as either \"ham\" (legitimate) or \"spam\". The following preprocessing steps are applied:\n",
    "\n",
    "* Lowercasing: Converts text to lowercase.\n",
    "* Tokenization: Splits text into words (tokens).\n",
    "* Alphanumeric Filtering: Removes non-alphanumeric tokens.\n",
    "* Stop Word Removal: Eliminates common words (e.g., \"the\", \"and\", \"is\").\n",
    "* Stemming: Reduces words to their root form (e.g., \"running\" to \"run\").\n",
    "\n",
    "**2. Method**\n",
    "\n",
    "The code uses the Multinomial Naive Bayes algorithm for text classification. The approach involves:\n",
    "\n",
    "* Feature Extraction: Converting preprocessed messages into numerical vectors using:\n",
    "    * Bag-of-Words (BoW): Word frequency vectors.\n",
    "    * TF-IDF: Weights words by frequency and inverse document frequency.\n",
    "* Model Training: Training a Multinomial Naive Bayes classifier.\n",
    "* Prediction: Predicting labels (ham or spam) for test data.\n",
    "* Evaluation: Assessing performance with metrics.\n",
    "\n",
    "**3. Experiment Design**\n",
    "\n",
    "The experiment:\n",
    "\n",
    "1.  Loads the SMS Spam Collection dataset.\n",
    "2.  Applies preprocessing steps.\n",
    "3.  Creates a vocabulary of unique words for BoW and TF-IDF.\n",
    "4.  Extracts BoW and TF-IDF features.\n",
    "5.  Splits data into 80/20 training/testing sets with stratification.\n",
    "6.  Trains and evaluates Naive Bayes on both feature sets.\n",
    "7.  Compares performance.\n",
    "\n",
    "**4. Hyperparameters**\n",
    "\n",
    "The Multinomial Naive Bayes classifier uses:\n",
    "\n",
    "* `alpha` (Smoothing parameter): Laplace smoothing for zero-frequency words (default: 1.0).\n",
    "\n",
    "**5. Evaluation Metrics**\n",
    "\n",
    "Performance is evaluated using:\n",
    "\n",
    "* Accuracy: Proportion of correctly classified messages.\n",
    "* Precision: Proportion of correctly classified spam out of all predicted spam.\n",
    "* Recall: Proportion of correctly classified spam out of all actual spam.\n",
    "* F1-score: Balanced measure of precision and recall.\n",
    "\n",
    "**6. Findings**\n",
    "\n",
    "The code evaluates the Multinomial Naive Bayes classifier on both BoW and TF-IDF representations of the text data. Here are the results:\n",
    "\n",
    "* **Evaluation of Naive Bayes classifier on BoW features:**\n",
    "    * Accuracy: 0.9758\n",
    "    * Precision: 0.9067\n",
    "    * Recall: 0.9128\n",
    "    * F1 Score: 0.9097\n",
    "* **Evaluation of Naive Bayes classifier on TF-IDF features:**\n",
    "    * Accuracy: 0.9435\n",
    "    * Precision: 0.7263\n",
    "    * Recall: 0.9262\n",
    "    * F1 Score: 0.8142\n",
    "\n",
    "As the results indicate, the Naive Bayes classifier performs better with BoW features than with TF-IDF features on this dataset. BoW achieves higher accuracy, precision, recall, and F1-score.\n",
    "\n",
    "**7. Drawbacks**\n",
    "\n",
    "* Simplicity of Naive Bayes: Assumes conditionally independent features, often violated in text.\n",
    "* Vocabulary Dependence: Performance depends on training data vocabulary; struggles with out-of-vocabulary words.\n",
    "* Limited Context: Ignores word order.\n",
    "\n",
    "**8. Potential Improvements**\n",
    "\n",
    "* Advanced Preprocessing: Explore lemmatization or n-grams.\n",
    "* Feature Engineering: Use word embeddings (e.g., Word2Vec) or metadata features (message length, sender info).\n",
    "* Model Selection: Experiment with SVMs, Logistic Regression, ensemble methods, or deep learning.\n",
    "* Hyperparameter Tuning: Optimize the Naive Bayes smoothing parameter and other model parameters.\n",
    "* Larger Dataset: Train on more diverse data.\n",
    "* Evaluation on Diverse Datasets: Assess performance across different spam datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jEykmdVPwqPA",
   "metadata": {
    "id": "jEykmdVPwqPA"
   },
   "source": [
    " ### Search Engine *(40 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-CRJj4Ypw1Z2",
   "metadata": {
    "id": "-CRJj4Ypw1Z2"
   },
   "source": [
    "Your boss is impressed with your spam detector and assigns you a new task. As part of improving internal tools, the company wants a search engine that can search through SMS messages and rank them by relevance. Implement the PageRank algorithm from scratch to score each SMS message based on its importance in the document graph.\n",
    "\n",
    "*   Compute TF-IDF vectors for all SMS messages (you can leverage previous implementation)\n",
    "*   Construct a document graph, where each node represents an SMS message and edges are the links between nodes.\n",
    "*  Implement the PageRank algorithm from scratch to assign an importance score to each SMS message based on its position in the document graph.\n",
    "\n",
    "#### Hint : You can use the previous dataset or any dataset from your choice.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G_2IblEnUeju",
   "metadata": {
    "id": "G_2IblEnUeju"
   },
   "source": [
    "## You might need the follwoing formulas for your implementation\n",
    "\n",
    "---\n",
    "\n",
    "### 1) Cosine Similarity Between Two Document Vectors\n",
    "\n",
    "Cosine similarity measures how similar two vectors are based on the angle between them:\n",
    "\n",
    "$$\n",
    "\\text{cosine\\_sim}(A, B) = \\frac{A \\cdot B}{\\|A\\| \\cdot \\|B\\|}\n",
    "$$\n",
    "\n",
    "- \\( A \\cdot B \\): Dot product of vectors \\( A \\) and \\( B \\)  \n",
    "- \\( \\|A\\| \\): Euclidean norm (magnitude) of vector \\( A \\)  \n",
    "- \\( \\|B\\| \\): Euclidean norm of vector \\( B \\)\n",
    "\n",
    "**Use case**: Comparing TF-IDF vectors to measure similarity between two messages.\n",
    "\n",
    "---\n",
    "\n",
    "### 2) PageRank of a Node \\( i \\)\n",
    "\n",
    "PageRank estimates the importance of a document based on its connections in a graph:\n",
    "\n",
    "$$\n",
    "PR(i) = \\frac{1 - d}{N} + d \\sum_{j \\in M(i)} \\frac{PR(j)}{L(j)}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- \\( PR(i) \\): PageRank score of node \\( i \\)  \n",
    "- \\( d \\): Damping factor (typically 0.85)  \n",
    "- \\( N \\): Total number of nodes (documents) in the graph  \n",
    "- \\( M(i) \\): Set of nodes that link to node \\( i \\)  \n",
    "- \\( L(j) \\): Number of outbound links from node \\( j \\)  \n",
    "\n",
    "**Interpretation**:  \n",
    "- A document is important if **important documents link to it**.  \n",
    "- The score is split among a node’s outbound links.  \n",
    "- The **teleportation term** $\\text(\\frac{1 - d}{N})$ accounts for random jumps, ensuring stability and fairness.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07f22845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data.\n",
      "Preprocessed messages.\n",
      "Calculated TF-IDF matrix.\n",
      "Constructed graph.\n",
      "Calculated PageRank scores.\n",
      "PageRank Results:\n",
      "Rank 1: Score = 0.0170, Message = Hmmm.. Thk sure got time to hop ard... Ya, can go 4 free abt... Muz call u to discuss liao......\n",
      "Rank 2: Score = 0.0162, Message = You'll not rcv any more msgs from the chat svc. For FREE Hardcore services text GO to: 69988 If u ge...\n",
      "Rank 3: Score = 0.0148, Message = HEY GIRL. HOW R U? HOPE U R WELL ME AN DEL R BAK! AGAIN LONG TIME NO C! GIVE ME A CALL SUM TIME FROM...\n",
      "Rank 4: Score = 0.0148, Message = Hi. Wk been ok - on hols now! Yes on for a bit of a run. Forgot that i have hairdressers appointment...\n",
      "Rank 5: Score = 0.0144, Message = I'm ok wif it cos i like 2 try new things. But i scared u dun like mah. Cos u said not too loud....\n",
      "Rank 6: Score = 0.0139, Message = Hi its Kate how is your evening? I hope i can see you tomorrow for a bit but i have to bloody babyjo...\n",
      "Rank 7: Score = 0.0139, Message = For real when u getting on yo? I only need 2 more tickets and one more jacket and I'm done. I alread...\n",
      "Rank 8: Score = 0.0138, Message = Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera f...\n",
      "Rank 9: Score = 0.0136, Message = Smile in Pleasure Smile in Pain Smile when trouble pours like Rain Smile when sum1 Hurts U Smile bec...\n",
      "Rank 10: Score = 0.0135, Message = You are a winner U have been specially selected 2 receive £1000 cash or a 4* holiday (flights inc) s...\n",
      "Rank 11: Score = 0.0135, Message = URGENT! Your Mobile No. was awarded £2000 Bonus Caller Prize on 5/9/03 This is our final try to cont...\n",
      "Rank 12: Score = 0.0133, Message = BangBabes Ur order is on the way. U SHOULD receive a Service Msg 2 download UR content. If U do not,...\n",
      "Rank 13: Score = 0.0132, Message = U don't know how stubborn I am. I didn't even want to go to the hospital. I kept telling Mark I'm no...\n",
      "Rank 14: Score = 0.0129, Message = Aft i finish my lunch then i go str down lor. Ard 3 smth lor. U finish ur lunch already?...\n",
      "Rank 15: Score = 0.0129, Message = You are a winner U have been specially selected 2 receive £1000 or a 4* holiday (flights inc) speak ...\n",
      "Rank 16: Score = 0.0128, Message = Havent planning to buy later. I check already lido only got 530 show in e afternoon. U finish work a...\n",
      "Rank 17: Score = 0.0124, Message = Eh u remember how 2 spell his name... Yes i did. He v naughty make until i v wet....\n",
      "Rank 18: Score = 0.0123, Message = Today is \"song dedicated day..\" Which song will u dedicate for me? Send this to all ur valuable frnd...\n",
      "Rank 19: Score = 0.0123, Message = I jus reached home. I go bathe first. But my sis using net tell u when she finishes k......\n",
      "Rank 20: Score = 0.0118, Message = U can call me now......\n",
      "Rank 21: Score = 0.0116, Message = Sunshine Quiz Wkly Q! Win a top Sony DVD player if u know which country the Algarve is in? Txt ansr ...\n",
      "Rank 22: Score = 0.0113, Message = U still going to the mall?...\n",
      "Rank 23: Score = 0.0110, Message = Congrats! 1 year special cinema pass for 2 is yours. call 09061209465 now! C Suprman V, Matrix3, Sta...\n",
      "Rank 24: Score = 0.0107, Message = Okay name ur price as long as its legal! Wen can I pick them up? Y u ave x ams xx...\n",
      "Rank 25: Score = 0.0105, Message = U dun say so early hor... U c already then say......\n",
      "Rank 26: Score = 0.0104, Message = Did u got that persons story...\n",
      "Rank 27: Score = 0.0102, Message = Ok lar... Joking wif u oni......\n",
      "Rank 28: Score = 0.0101, Message = Yeah he got in at 2 and was v apologetic. n had fallen out and she was actin like spoilt child and h...\n",
      "Rank 29: Score = 0.0101, Message = Fine if thats the way u feel. Thats the way its gota b...\n",
      "Rank 30: Score = 0.0098, Message = Hi! You just spoke to MANEESHA V. We'd like to know if you were satisfied with the experience. Reply...\n",
      "Rank 31: Score = 0.0095, Message = You are everywhere dirt, on the floor, the windows, even on my shirt. And sometimes when i open my m...\n",
      "Rank 32: Score = 0.0095, Message = Bloody hell, cant believe you forgot my surname Mr . Ill give u a clue, its spanish and begins with ...\n",
      "Rank 33: Score = 0.0094, Message = Want 2 get laid tonight? Want real Dogging locations sent direct 2 ur mob? Join the UK's largest Dog...\n",
      "Rank 34: Score = 0.0092, Message = Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entr...\n",
      "Rank 35: Score = 0.0092, Message = Anything lor... U decide......\n",
      "Rank 36: Score = 0.0092, Message = Lol no. U can trust me....\n",
      "Rank 37: Score = 0.0091, Message = Watching telugu movie..wat abt u?...\n",
      "Rank 38: Score = 0.0089, Message = Turns out my friends are staying for the whole show and won't be back til ~ &lt;#&gt; , so feel free...\n",
      "Rank 39: Score = 0.0087, Message = Let me know when you've got the money so carlos can make the call...\n",
      "Rank 40: Score = 0.0086, Message = 07732584351 - Rodger Burns - MSG = We tried to call you re your reply to our sms for a free nokia mo...\n",
      "Rank 41: Score = 0.0083, Message = FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it s...\n",
      "Rank 42: Score = 0.0081, Message = Hello! How's you and how did saturday go? I was just texting to see if you'd decided to do anything ...\n",
      "Rank 43: Score = 0.0079, Message = England v Macedonia - dont miss the goals/team news. Txt ur national team to 87077 eg ENGLAND to 870...\n",
      "Rank 44: Score = 0.0077, Message = I‘m going to try for 2 months ha ha only joking...\n",
      "Rank 45: Score = 0.0077, Message = URGENT! You have won a 1 week FREE membership in our £100,000 Prize Jackpot! Txt the word: CLAIM to ...\n",
      "Rank 46: Score = 0.0075, Message = Yup... Ok i go home look at the timings then i msg ü again... Xuhui going to learn on 2nd may too bu...\n",
      "Rank 47: Score = 0.0074, Message = Got c... I lazy to type... I forgot ü in lect... I saw a pouch but like not v nice......\n",
      "Rank 48: Score = 0.0073, Message = GENT! We are trying to contact you. Last weekends draw shows that you won a £1000 prize GUARANTEED. ...\n",
      "Rank 49: Score = 0.0073, Message = URGENT! We are trying to contact you. Last weekends draw shows that you have won a £900 prize GUARAN...\n",
      "Rank 50: Score = 0.0073, Message = Yup i thk cine is better cos no need 2 go down 2 plaza mah....\n",
      "Rank 51: Score = 0.0073, Message = Yes I started to send requests to make it but pain came back so I'm back in bed. Double coins at the...\n",
      "Rank 52: Score = 0.0073, Message = Todays Voda numbers ending 7548 are selected to receive a $350 award. If you have a match please cal...\n",
      "Rank 53: Score = 0.0068, Message = Just so that you know,yetunde hasn't sent money yet. I just sent her a text not to bother sending. S...\n",
      "Rank 54: Score = 0.0065, Message = Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got a...\n",
      "Rank 55: Score = 0.0064, Message = I'm sorry. I've joined the league of people that dont keep in touch. You mean a great deal to me. Yo...\n",
      "Rank 56: Score = 0.0063, Message = PRIVATE! Your 2004 Account Statement for 07742676969 shows 786 unredeemed Bonus Points. To claim cal...\n",
      "Rank 57: Score = 0.0062, Message = SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6day...\n",
      "Rank 58: Score = 0.0061, Message = Your free ringtone is waiting to be collected. Simply text the password \"MIX\" to 85069 to verify. Ge...\n",
      "Rank 59: Score = 0.0061, Message = Please call our customer service representative on 0800 169 6031 between 10am-9pm as you have WON a ...\n",
      "Rank 60: Score = 0.0061, Message = Please call our customer service representative on FREEPHONE 0808 145 4742 between 9am-11pm as you h...\n",
      "Rank 61: Score = 0.0061, Message = I am waiting machan. Call me once you free....\n",
      "Rank 62: Score = 0.0061, Message = Customer service annoncement. You have a New Years delivery waiting for you. Please call 07046744435...\n",
      "Rank 63: Score = 0.0060, Message = I know! Grumpy old people. My mom was like you better not be lying. Then again I am always the one t...\n",
      "Rank 64: Score = 0.0060, Message = Urgent UR awarded a complimentary trip to EuroDisinc Trav, Aco&Entry41 Or £1000. To claim txt DIS to...\n",
      "Rank 65: Score = 0.0060, Message = WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim...\n",
      "Rank 66: Score = 0.0059, Message = Hello, my love. What are you doing? Did you get to that interview today? Are you you happy? Are you ...\n",
      "Rank 67: Score = 0.0059, Message = Have you got Xmas radio times. If not i will get it now...\n",
      "Rank 68: Score = 0.0059, Message = Hello handsome ! Are you finding that job ? Not being lazy ? Working towards getting back that net f...\n",
      "Rank 69: Score = 0.0059, Message = Keep yourself safe for me because I need you and I miss you already and I envy everyone that see's y...\n",
      "Rank 70: Score = 0.0057, Message = Ummma.will call after check in.our life will begin from qatar so pls pray very hard....\n",
      "Rank 71: Score = 0.0057, Message = A gram usually runs like  &lt;#&gt; , a half eighth is smarter though and gets you almost a whole se...\n",
      "Rank 72: Score = 0.0057, Message = Ela kano.,il download, come wen ur free.....\n",
      "Rank 73: Score = 0.0057, Message = Just forced myself to eat a slice. I'm really not hungry tho. This sucks. Mark is getting worried. H...\n",
      "Rank 74: Score = 0.0056, Message = Wow. I never realized that you were so embarassed by your accomodations. I thought you liked it, sin...\n",
      "Rank 75: Score = 0.0055, Message = Ok... Ur typical reply......\n",
      "Rank 76: Score = 0.0055, Message = Sorry to be a pain. Is it ok if we meet another night? I spent late afternoon in casualty and that m...\n",
      "Rank 77: Score = 0.0053, Message = As a valued customer, I am pleased to advise you that following recent review of your Mob No. you ar...\n",
      "Rank 78: Score = 0.0053, Message = I call you later, don't have network. If urgnt, sms me....\n",
      "Rank 79: Score = 0.0052, Message = A swt thought: \"Nver get tired of doing little things 4 lovable persons..\" Coz..somtimes those littl...\n",
      "Rank 80: Score = 0.0052, Message = No calls..messages..missed calls...\n",
      "Rank 81: Score = 0.0052, Message = Ok lar i double check wif da hair dresser already he said wun cut v short. He said will cut until i ...\n",
      "Rank 82: Score = 0.0052, Message = Sorry, I'll call later in meeting....\n",
      "Rank 83: Score = 0.0051, Message = Sorry, I'll call later...\n",
      "Rank 84: Score = 0.0051, Message = Pls go ahead with watts. I just wanted to be sure. Do have a great weekend. Abiola...\n",
      "Rank 85: Score = 0.0050, Message = You lifted my hopes with the offer of money. I am in need. Especially when the end of the month appr...\n",
      "Rank 86: Score = 0.0050, Message = I am going to sao mu today. Will be done only at 12...\n",
      "Rank 87: Score = 0.0050, Message = Thanks for your subscription to Ringtone UK your mobile will be charged £5/month Please confirm by r...\n",
      "Rank 88: Score = 0.0050, Message = Wa, ur openin sentence very formal... Anyway, i'm fine too, juz tt i'm eatin too much n puttin on we...\n",
      "Rank 89: Score = 0.0048, Message = -PLS STOP bootydelious (32/F) is inviting you to be her friend. Reply YES-434 or NO-434 See her: www...\n",
      "Rank 90: Score = 0.0047, Message = Great! I hope you like your man well endowed. I am  &lt;#&gt;  inches......\n",
      "Rank 91: Score = 0.0046, Message = FreeMsg Why haven't you replied to my text? I'm Randy, sexy, female and live local. Luv to hear from...\n",
      "Rank 92: Score = 0.0046, Message = Dear, will call Tmorrow.pls accomodate....\n",
      "Rank 93: Score = 0.0046, Message = Your gonna have to pick up a $1 burger for yourself on your way home. I can't even move. Pain is kil...\n",
      "Rank 94: Score = 0.0045, Message = He is there. You call and meet him...\n",
      "Rank 95: Score = 0.0045, Message = Ahhh. Work. I vaguely remember that! What does it feel like? Lol...\n",
      "Rank 96: Score = 0.0044, Message = I place all ur points on e cultures module already....\n",
      "Rank 97: Score = 0.0043, Message = Wait that's still not all that clear, were you not sure about me being sarcastic or that that's why ...\n",
      "Rank 98: Score = 0.0043, Message = K. Did you call me just now ah?...\n",
      "Rank 99: Score = 0.0043, Message = Text her. If she doesnt reply let me know so i can have her log in...\n",
      "Rank 100: Score = 0.0043, Message = Even my brother is not like to speak with me. They treat me like aids patent....\n",
      "Rank 101: Score = 0.0039, Message = Fair enough, anything going on?...\n",
      "Rank 102: Score = 0.0038, Message = Goodo! Yes we must speak friday - egg-potato ratio for tortilla needed!...\n",
      "Rank 103: Score = 0.0038, Message = I know you are. Can you pls open the back?...\n",
      "Rank 104: Score = 0.0038, Message = Great escape. I fancy the bridge but needs her lager. See you tomo...\n",
      "Rank 105: Score = 0.0037, Message = Did I forget to tell you ? I want you , I need you, I crave you ... But most of all ... I love you m...\n",
      "Rank 106: Score = 0.0037, Message = Aight, I'll hit you up when I get some cash...\n",
      "Rank 107: Score = 0.0036, Message = Yes see ya not on the dot...\n",
      "Rank 108: Score = 0.0036, Message = I'm back &amp; we're packing the car now, I'll let you know if there's room...\n",
      "Rank 109: Score = 0.0036, Message = I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enou...\n",
      "Rank 110: Score = 0.0035, Message = Ok i am on the way to home hi hi...\n",
      "Rank 111: Score = 0.0034, Message = Going on nothing great.bye...\n",
      "Rank 112: Score = 0.0033, Message = I like you peoples very much:) but am very shy pa....\n",
      "Rank 113: Score = 0.0033, Message = Going for dinner.msg you after....\n",
      "Rank 114: Score = 0.0033, Message = Ü predict wat time ü'll finish buying?...\n",
      "Rank 115: Score = 0.0033, Message = As I entered my cabin my PA said, '' Happy B'day Boss !!''. I felt special. She askd me 4 lunch. Aft...\n",
      "Rank 116: Score = 0.0031, Message = Hi frnd, which is best way to avoid missunderstding wit our beloved one's?...\n",
      "Rank 117: Score = 0.0031, Message = Please don't text me anymore. I have nothing else to say....\n",
      "Rank 118: Score = 0.0031, Message = Oops, I'll let you know when my roommate's done...\n",
      "Rank 119: Score = 0.0031, Message = What you thinked about me. First time you saw me in class....\n",
      "Rank 120: Score = 0.0030, Message = Didn't you get hep b immunisation in nigeria....\n",
      "Rank 121: Score = 0.0030, Message = XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here>> h...\n",
      "Rank 122: Score = 0.0029, Message = wow. You're right! I didn't mean to do that. I guess once i gave up on boston men and changed my sea...\n",
      "Rank 123: Score = 0.0029, Message = Do you know what Mallika Sherawat did yesterday? Find out now @  &lt;URL&gt;...\n",
      "Rank 124: Score = 0.0029, Message = i see. When we finish we have loads of loans to pay...\n",
      "Rank 125: Score = 0.0028, Message = Sorry my roommates took forever, it ok if I come by now?...\n",
      "Rank 126: Score = 0.0028, Message = K, text me when you're on the way...\n",
      "Rank 127: Score = 0.0027, Message = SMS. ac Sptv: The New Jersey Devils and the Detroit Red Wings play Ice Hockey. Correct or Incorrect?...\n",
      "Rank 128: Score = 0.0027, Message = Did you catch the bus ? Are you frying an egg ? Did you make a tea? Are you eating your mom's left o...\n",
      "Rank 129: Score = 0.0026, Message = I've been searching for the right words to thank you for this breather. I promise i wont take your h...\n",
      "Rank 130: Score = 0.0026, Message = What time you coming down later?...\n",
      "Rank 131: Score = 0.0025, Message = Its not the same here. Still looking for a job. How much do Ta's earn there....\n",
      "Rank 132: Score = 0.0025, Message = I'm so in love with you. I'm excited each day i spend with you. You make me so happy....\n",
      "Rank 133: Score = 0.0025, Message = I see the letter B on my car...\n",
      "Rank 134: Score = 0.0025, Message = How are you doing? Hope you've settled in for the new school year. Just wishin you a gr8 day...\n",
      "Rank 135: Score = 0.0025, Message = I'm still looking for a car to buy. And have not gone 4the driving test yet....\n",
      "Rank 136: Score = 0.0024, Message = Well, i'm gonna finish my bath now. Have a good...fine night....\n",
      "Rank 137: Score = 0.0023, Message = HI BABE IM AT HOME NOW WANNA DO SOMETHING? XX...\n",
      "Rank 138: Score = 0.0023, Message = K fyi x has a ride early tomorrow morning but he's crashing at our place tonight...\n",
      "Rank 139: Score = 0.0023, Message = Sindu got job in birla soft .....\n",
      "Rank 140: Score = 0.0022, Message = I see a cup of coffee animation...\n",
      "Rank 141: Score = 0.0021, Message = I plane to give on this month end....\n",
      "Rank 142: Score = 0.0021, Message = I'm really not up to it still tonight babe...\n",
      "Rank 143: Score = 0.0020, Message = It will stop on itself. I however suggest she stays with someone that will be able to give ors for e...\n",
      "Rank 144: Score = 0.0019, Message = Yeah hopefully, if tyler can't do it I could maybe ask around a bit...\n",
      "Rank 145: Score = 0.0019, Message = Sir, I need AXIS BANK account no and bank address....\n",
      "Rank 146: Score = 0.0019, Message = WHO ARE YOU SEEING?...\n",
      "Rank 147: Score = 0.0018, Message = Umma my life and vava umma love you lot dear...\n",
      "Rank 148: Score = 0.0017, Message = Hi :)finally i completed the course:)...\n",
      "Rank 149: Score = 0.0017, Message = K tell me anything about you....\n",
      "Rank 150: Score = 0.0016, Message = Yes :)it completely in out of form:)clark also utter waste....\n",
      "Rank 151: Score = 0.0016, Message = Yes..gauti and sehwag out of odi series....\n",
      "Rank 152: Score = 0.0015, Message = Dont worry. I guess he's busy....\n",
      "Rank 153: Score = 0.0015, Message = Thanks a lot for your wishes on my birthday. Thanks you for making my birthday truly memorable....\n",
      "Rank 154: Score = 0.0015, Message = Did you hear about the new \"Divorce Barbie\"? It comes with all of Ken's stuff!...\n",
      "Rank 155: Score = 0.0015, Message = So ü pay first lar... Then when is da stock comin......\n",
      "Rank 156: Score = 0.0014, Message = Gud mrng dear hav a nice day...\n",
      "Rank 157: Score = 0.0013, Message = New car and house for my parents.:)i have only new job in hand:)...\n",
      "Rank 158: Score = 0.0013, Message = Nah I don't think he goes to usf, he lives around here though...\n",
      "Rank 159: Score = 0.0013, Message = K..k:)how much does it cost?...\n",
      "Rank 160: Score = 0.0012, Message = Ffffffffff. Alright no way I can meet up with you sooner?...\n",
      "Rank 161: Score = 0.0012, Message = Ha ha ha good joke. Girls are situation seekers....\n",
      "Rank 162: Score = 0.0012, Message = First answer my question....\n",
      "Rank 163: Score = 0.0011, Message = As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertu...\n",
      "Rank 164: Score = 0.0011, Message = As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertu...\n",
      "Rank 165: Score = 0.0011, Message = As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertu...\n",
      "Rank 166: Score = 0.0011, Message = Finished class where are you....\n",
      "Rank 167: Score = 0.0011, Message = Hmm...my uncle just informed me that he's paying the school directly. So pls buy food....\n",
      "Rank 168: Score = 0.0011, Message = K..i deleted my contact that why?...\n",
      "Rank 169: Score = 0.0011, Message = Does not operate after  &lt;#&gt;  or what...\n",
      "Rank 170: Score = 0.0011, Message = Whats the staff name who is taking class for us?...\n",
      "Rank 171: Score = 0.0010, Message = I'm home....\n",
      "Rank 172: Score = 0.0010, Message = Lol your always so convincing....\n",
      "Rank 173: Score = 0.0009, Message = is your hamster dead? Hey so tmr i meet you at 1pm orchard mrt?...\n",
      "Rank 174: Score = 0.0009, Message = No no. I will check all rooms befor activities...\n",
      "Rank 175: Score = 0.0009, Message = Its a part of checking IQ...\n",
      "Rank 176: Score = 0.0009, Message = Yup next stop....\n",
      "Rank 177: Score = 0.0008, Message = here is my new address -apples&pairs&all that malarky...\n",
      "Rank 178: Score = 0.0008, Message = Oh k...i'm watching here:)...\n",
      "Rank 179: Score = 0.0008, Message = Sir, Waiting for your mail....\n",
      "Rank 180: Score = 0.0008, Message = Tell where you reached...\n",
      "Rank 181: Score = 0.0007, Message = Is that seriously how you spell his name?...\n",
      "Rank 182: Score = 0.0007, Message = Yeah do! Don‘t stand to close tho- you‘ll catch something!...\n",
      "Rank 183: Score = 0.0006, Message = Wah lucky man... Then can save money... Hee......\n",
      "Rank 184: Score = 0.0006, Message = Aaooooright are you at work?...\n",
      "Rank 185: Score = 0.0005, Message = You will be in the place of that man...\n",
      "Rank 186: Score = 0.0005, Message = K..k:)where are you?how did you performed?...\n",
      "Rank 187: Score = 0.0005, Message = Are you unique enough? Find out from 30th August. www.areyouunique.co.uk...\n",
      "Rank 188: Score = 0.0004, Message = Good stuff, will do....\n",
      "Rank 189: Score = 0.0004, Message = The wine is flowing and i'm i have nevering.....\n",
      "Rank 190: Score = 0.0003, Message = Are you there in room....\n",
      "Rank 191: Score = 0.0002, Message = How would my ip address test that considering my computer isn't a minecraft server...\n",
      "Rank 192: Score = 0.0002, Message = Haha awesome, be there in a minute...\n",
      "Rank 193: Score = 0.0001, Message = Thats cool. i am a gentleman and will treat you with dignity and respect....\n",
      "Rank 194: Score = 0.0001, Message = ok. I am a gentleman and will treat you with dignity and respect....\n",
      "Rank 195: Score = 0.0000, Message = I'm leaving my house now......\n",
      "Rank 196: Score = 0.0000, Message = He will, you guys close?...\n",
      "Rank 197: Score = 0.0000, Message = I HAVE A DATE ON SUNDAY WITH WILL!!...\n",
      "Rank 198: Score = 0.0000, Message = What is the plural of the noun research?...\n",
      "Rank 199: Score = 0.0000, Message = I only haf msn. It's yijue@hotmail.com...\n",
      "Rank 200: Score = 0.0000, Message = For fear of fainting with the of all that housework you just did? Quick have a cuppa...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "\n",
    "def load_data(filepath):\n",
    "    messages = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            parts = line.split(None, 1)\n",
    "            if len(parts) == 2:\n",
    "                messages.append(parts[1].strip())\n",
    "    return messages\n",
    "\n",
    "def preprocess(messages):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    porter = PorterStemmer()\n",
    "    processed_messages = []\n",
    "    for message in messages:\n",
    "        tokens = nltk.word_tokenize(message.lower())\n",
    "        alphanumeric_tokens = [token for token in tokens if re.match(r'[a-zA-Z0-9]+$', token)]\n",
    "        tokens_no_stopwords = [token for token in alphanumeric_tokens if token not in stop_words]\n",
    "        stemmed_tokens = [porter.stem(token) for token in tokens_no_stopwords]\n",
    "        processed_messages.append(stemmed_tokens)\n",
    "    return processed_messages\n",
    "\n",
    "def tf_idf(documents):\n",
    "    num_documents = len(documents)\n",
    "    vocabulary = sorted(list(set(word for doc in documents for word in doc)))\n",
    "    vocabulary_size = len(vocabulary)\n",
    "    word_to_index = {word: i for i, word in enumerate(vocabulary)}\n",
    "\n",
    "    tf_matrix = np.zeros((num_documents, vocabulary_size))\n",
    "    for i, document in enumerate(documents):\n",
    "        for word in document:\n",
    "            if word in word_to_index:\n",
    "                index = word_to_index[word]\n",
    "                tf_matrix[i, index] += 1\n",
    "\n",
    "    document_frequency = np.zeros(vocabulary_size)\n",
    "    for i, word in enumerate(vocabulary):\n",
    "        for document in documents:\n",
    "            if word in document:\n",
    "                document_frequency[i] += 1\n",
    "\n",
    "    idf = np.log(num_documents / (document_frequency + 1))\n",
    "    tfidf_matrix = tf_matrix * idf\n",
    "    return tfidf_matrix\n",
    "\n",
    "\n",
    "def construct_graph(tfidf_matrix):\n",
    "    similarity_matrix = cosine_similarity(tfidf_matrix)\n",
    "    return similarity_matrix\n",
    "\n",
    "def pagerank(graph, damping_factor=0.85, max_iterations=100):\n",
    "    num_nodes = len(graph)  # Number of nodes in the graph\n",
    "    node_ranks = [1.0 / num_nodes] * num_nodes  # Initialize ranks to 1/N for each node\n",
    "\n",
    "    for iteration in range(max_iterations):\n",
    "        new_node_ranks = [0.0] * num_nodes  # Store updated ranks for each node\n",
    "\n",
    "        for i in range(num_nodes):  # Iterate through each node i\n",
    "            for j in range(num_nodes):  # Iterate through each node j to find incoming links to i\n",
    "                if graph[j][i] > 0:  # If there's a link from node j to node i\n",
    "                    new_node_ranks[i] += node_ranks[j] / sum(graph[j])  # Add j's contribution to i's rank\n",
    "\n",
    "        for i in range(num_nodes):\n",
    "            new_node_ranks[i] = (1 - damping_factor) / num_nodes + damping_factor * new_node_ranks[i]\\\n",
    "            \n",
    "        node_ranks = new_node_ranks  # Update ranks for the next iteration\n",
    "\n",
    "    return node_ranks  # Return the final PageRank scores\n",
    "\n",
    "def normalize_pagerank_scores(pagerank_scores):\n",
    "    \"\"\"Normalizes PageRank scores so they sum to 1.\"\"\"\n",
    "    total_score = sum(pagerank_scores)\n",
    "    normalized_scores = [score / total_score for score in pagerank_scores]\n",
    "    return normalized_scores\n",
    "\n",
    "filepath = 'sms_spam_collection\\Reduced_SMSSpamCollection'\n",
    "messages = load_data(filepath)\n",
    "print(\"Loaded data.\")  # Print statement\n",
    "processed_messages = preprocess(messages)\n",
    "print(\"Preprocessed messages.\")  # Print statement\n",
    "tfidf_matrix = tf_idf(processed_messages)\n",
    "print(\"Calculated TF-IDF matrix.\")  # Print statement\n",
    "graph = construct_graph(tfidf_matrix)\n",
    "print(\"Constructed graph.\")  # Print statement\n",
    "ranks = pagerank(graph)\n",
    "normalized_scores = normalize_pagerank_scores(ranks)\n",
    "print(\"Calculated PageRank scores.\")  # Print statement\n",
    "\n",
    "# Print results (most relevant messages first)\n",
    "message_ranks = list(zip(messages, normalized_scores))\n",
    "message_ranks.sort(key=lambda x: x[1], reverse=True)\n",
    "print(\"PageRank Results:\")\n",
    "for i, (message, rank) in enumerate(message_ranks):\n",
    "    print(f\"Rank {i + 1}: Score = {rank:.4f}, Message = {message[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79fc036",
   "metadata": {},
   "source": [
    "## PageRank Implementation Summary\n",
    "\n",
    "Here's a summary of what the code does, the thinking behind it, the findings, and what the PageRank tells us:\n",
    "\n",
    "### Workflow\n",
    "\n",
    "1.  **Load Data:**\n",
    "    * SMS messages are loaded from the `Reduced_SMSSpamCollection` file. The `load_data` function reads this file and extracts the message content, ignoring the labels.\n",
    "\n",
    "2.  **Preprocess Messages:**\n",
    "    * Messages are converted to lowercase.\n",
    "    * Stop words are removed.\n",
    "    * Words are stemmed to their root form.  The `preprocess` function cleans and standardizes the text data.\n",
    "\n",
    "3.  **Calculate TF-IDF Matrix:**\n",
    "    * The TF-IDF (Term Frequency-Inverse Document Frequency) matrix is calculated.\n",
    "    * TF-IDF measures word importance.\n",
    "    * This step transforms the text into a numerical representation.\n",
    "\n",
    "4.  **Construct Graph:**\n",
    "    * A graph is constructed where:\n",
    "        * Each SMS message is a node.\n",
    "        * Edges represent cosine similarity between TF-IDF vectors.\n",
    "    * The graph represents message relationships based on word usage.\n",
    "\n",
    "5.  **Calculate PageRank Scores:**\n",
    "    * The PageRank algorithm is applied to the graph.\n",
    "    * This assigns an \"importance\" score to each message.\n",
    "    * PageRank ranks messages based on their connections in the graph.\n",
    "\n",
    "6.  **Normalize PageRank Scores:**\n",
    "    * Raw PageRank scores are normalized.\n",
    "    * This creates a probability distribution.\n",
    "\n",
    "7.  **Print Results:**\n",
    "    * Messages are ranked by normalized PageRank scores.\n",
    "    * The output displays the most \"important\" messages.\n",
    "\n",
    "### Thinking Behind It\n",
    "\n",
    "* The code uses PageRank to identify \"important\" SMS messages, similar to how PageRank was used to rank web pages.\n",
    "* A message's importance is determined by its similarity to other important messages.\n",
    "* TF-IDF represents message content, enabling similarity calculation.\n",
    "* The graph representation allows PageRank to find influential messages.\n",
    "\n",
    "### Findings\n",
    "\n",
    "* The code calculates a PageRank score for each message, indicating its relative importance.\n",
    "* Messages similar to many other messages receive higher PageRank scores.\n",
    "* The output ranks messages by their PageRank scores.\n",
    "\n",
    "### What Does PageRank Tell Us?\n",
    "\n",
    "* PageRank identifies \"central\" or \"influential\" messages.\n",
    "* A high PageRank score suggests similarity to many other messages.\n",
    "* In an SMS dataset:\n",
    "    * Messages in a common theme or conversation may rank higher.\n",
    "    * Spam campaigns with similar messages may also rank higher.\n",
    "    * Unique or isolated messages may rank lower.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cbc82a",
   "metadata": {
    "id": "55cbc82a"
   },
   "source": [
    "### Additional Experiments *(5 additional points - <span style=\"color: red;\">Optional</span>)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5820d4",
   "metadata": {
    "id": "9b5820d4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
